{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pp68FAQf9aMN"
   },
   "source": [
    "# Sarcasm Detection\n",
    " **Acknowledgement**\n",
    "\n",
    "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
    "\n",
    "**Required Files given in below link.**\n",
    "\n",
    "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3Wj_mIZ8S3K"
   },
   "source": [
    "## Install `Tensorflow2.0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW2Uk8otQvi8"
   },
   "outputs": [],
   "source": [
    "#!!pip uninstall tensorflow\n",
    "#!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9kv9tyJ77eF"
   },
   "source": [
    "## Get Required Files from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "D0O_n6OIEVyL",
    "outputId": "3d02fc9c-2fb9-4e05-d74a-a0f457b5e601"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('4/ygFZvHWGr1TPWtpCFD73vGK4xAJSLpF6CnbWZjOuBHggP8-4y4ZZZHo/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgRpOvFMjKR"
   },
   "outputs": [],
   "source": [
    "#Set your project path \n",
    "project_path =  4/ygFZvHWGr1TPWtpCFD73vGK4xAJSLpF6CnbWZjOuBHggP8-4y4ZZZHo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXYwajPeQbRq"
   },
   "source": [
    "#**## Reading and Exploring Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAk6BRUh8CqL"
   },
   "source": [
    "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 8 marks)\n",
    "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***********************************************************\")\n",
    "print(\"**************  Loading Dataset and Analysis **************\")\n",
    "print(\"***********************************************************\")\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "def plot_roc(model, X_test, y_test):\n",
    "    proba = model.predict_proba(X_test)\n",
    "    fpr,tpr, threshold = roc_curve(y_test,proba)\n",
    "    auc_val = auc(fpr,tpr)\n",
    "\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.title('Reciever Operating Charactaristics')\n",
    "    plt.plot(fpr,tpr,'b',label = 'AUC = %0.2f' % auc_val)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.xlabel('False positive rate')\n",
    "    \n",
    "#This is a function that reads a pre-trained embeddings file and returns a matrix embeddings for the dataset we are working with.\n",
    "#Inputs are the filepath, the size of the embeddings (should match the pre-trained ones) and the word_indices as created by a tokenizer on our data\n",
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***********************************************************\")\n",
    "print(\"**************  Loading Dataset and Analysis **************\")\n",
    "print(\"***********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StSLB-T8PuGr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "dataset = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***************************************************************\")\n",
    "print(\"**************  Buliding functions for Data Cleaning **********\")\n",
    "print(\"***************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Punctuations and change words to lower case\n",
    "def remove_punctuations(text):    \n",
    "    words=[word.lower() for word in text.split()] \n",
    "    words=[w for word in words for w in re.sub(r'[^\\w\\s]','',word).split()]    \n",
    "    return words\n",
    "\n",
    "### Remove StopWords\n",
    "stop = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    modified_word_list=[word for word in text if word not in stop]\n",
    "    return modified_word_list\n",
    "\n",
    "### Stemming of Words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "st=PorterStemmer()\n",
    "def Stemming(text):\n",
    "    stemmed_words=[st.stem(word) for word in text] \n",
    "    return stemmed_words\n",
    "\n",
    "### Recreating the sentence\n",
    "def Recreate(text):\n",
    "    word=\" \".join(text)\n",
    "    return word\n",
    "\n",
    "def Cleaning(text):\n",
    "    text_punctuation_removed=remove_punctuations(text)\n",
    "    text_stopword_removed=remove_stopwords(text_punctuation_removed)\n",
    "    # text_stemmed=Stemming(text_stopword_removed)\n",
    "    final_text=Recreate(text_stopword_removed)\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*******************************************************\")\n",
    "print(\"**************  SentimentIntensityAnalyzer ************\")\n",
    "print(\"*******************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_model = SentimentIntensityAnalyzer()\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def sentiment_classification(scores):\n",
    "    compound_score = scores['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        sentiment = 'positive'\n",
    "    elif compound_score <= - 0.05:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(0, len(dataset)):\n",
    "    sentences.append(dataset['headline'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_output= []\n",
    "for sent in sentences[:10]:\n",
    "    scores = vader_model.polarity_scores(sent)\n",
    "    system_output.append(sentiment_classification(scores))\n",
    "    print()\n",
    "    print('Input sentence:', sent)\n",
    "    print('Vader output:', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input sentence: former versace store clerk sues over secret 'black code' for minority shoppers\n",
    "Vader output: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
    "\n",
    "Input sentence: the 'roseanne' revival catches up to our thorny political mood, for better and worse\n",
    "Vader output: {'neg': 0.272, 'neu': 0.576, 'pos': 0.152, 'compound': -0.3182}\n",
    "\n",
    "Input sentence: mom starting to fear son's web series closest thing she will have to grandchild\n",
    "Vader output: {'neg': 0.198, 'neu': 0.802, 'pos': 0.0, 'compound': -0.4939}\n",
    "\n",
    "Input sentence: boehner just wants wife to listen, not come up with alternative debt-reduction ideas\n",
    "Vader output: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
    "\n",
    "Input sentence: j.k. rowling wishes snape happy birthday in the most magical way\n",
    "Vader output: {'neg': 0.0, 'neu': 0.629, 'pos': 0.371, 'compound': 0.6486}\n",
    "\n",
    "Input sentence: advancing the world's women\n",
    "Vader output: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
    "\n",
    "Input sentence: the fascinating case for eating lab-grown meat\n",
    "Vader output: {'neg': 0.0, 'neu': 0.632, 'pos': 0.368, 'compound': 0.5423}\n",
    "\n",
    "Input sentence: this ceo will send your kids to school, if you work for his company\n",
    "Vader output: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
    "\n",
    "Input sentence: top snake handler leaves sinking huckabee campaign\n",
    "Vader output: {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.2023}\n",
    "\n",
    "Input sentence: friday's morning email: inside trump's presser for the ages\n",
    "Vader output: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_huffington = 0\n",
    "num_onion = 0\n",
    "num_sarcastic = 0\n",
    "num_non_sarcastic = 0\n",
    "for i in range(0, len(dataset)):\n",
    "    if \"huffingtonpost\" in dataset['article_link'][i]:\n",
    "        num_huffington+=1\n",
    "    if \"theonion\" in dataset['article_link'][i]:\n",
    "        num_onion+=1\n",
    "    if dataset['is_sarcastic'][i] == 1:\n",
    "        num_sarcastic+=1\n",
    "    else:\n",
    "        num_non_sarcastic+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*******************************************************\")\n",
    "print(\"**************  Insight Of the given Data* ************\")\n",
    "print(\"*******************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to plot\n",
    "n_groups = 2\n",
    "group_news = (num_huffington, num_onion)\n",
    "group_sarcasm  = (len(dataset)-num_sarcastic-num_non_sarcastic, num_sarcastic)\n",
    "group_non_sarcasm = (num_non_sarcastic, len(dataset)-num_sarcastic-num_non_sarcastic)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.20\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, group_news, bar_width,\n",
    "alpha=opacity,\n",
    "color='y',\n",
    "label='Total number of headlines')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, group_sarcasm , bar_width,\n",
    "alpha=opacity,\n",
    "color='c',\n",
    "label='Is Sarcastic')\n",
    "\n",
    "\n",
    "rects3 = plt.bar(index + 2*bar_width, group_non_sarcasm , bar_width,\n",
    "alpha=opacity,\n",
    "color='m',\n",
    "label='Is Not Sarcastic')\n",
    "\n",
    " \n",
    "plt.xlabel('Websites')\n",
    "plt.ylabel('Number of headlines')\n",
    "plt.title('Number of headlines by websites')\n",
    "plt.xticks(index + bar_width, ('Huffington', 'The Onion'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('Sarcasm_news_data1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*******************************************************\")\n",
    "print(\"************** Function to Clean the Text  ************\")\n",
    "print(\"*******************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    ## Stemming\n",
    "    text = text.split()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.txt',sep='\\t',header=None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning data and preprocessing.................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(dataset['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_headline'] = dataset['headline'].apply(remove_punctuations)\n",
    "dataset['clean_headline'] = dataset['clean_headline'].apply(Recreate)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "corpus = []\n",
    "nlp = spacy.load('en')\n",
    "for i, headline in enumerate(dataset['headline']):\n",
    "    doc = nlp(headline)\n",
    "    review = dataset['headline'][i] \n",
    "    tokens = [word.lemma_.lower() for word in doc\n",
    "        if len(word) > 3 and not (word.is_stop | word.is_punct | word.is_digit)]\n",
    "    review = \" \".join(tokens)\n",
    "    corpus.append(review) # add it to the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader_model = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "for headline in corpus:\n",
    "    scores = vader_model.polarity_scores(headline)\n",
    "    scores_array = [scores['neg'],scores['neu'],scores['pos'],scores['compound']]\n",
    "    sentiments.append(scores_array)\n",
    "\n",
    "sentiment_array = np.array([np.array(x) for x in sentiments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((sentiment_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**********************************************\")\n",
    "print(\"************** Bag of Words Model ************\")\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words model\n",
    "y = dataset.iloc[:, 2]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "features_n = range(2800, 3500, 100) # list of different max vectors to try\n",
    "scores = []\n",
    "\n",
    "for i in features_n:\n",
    "    \n",
    "    #Td-idf\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3),max_features = i)\n",
    "    X = tf.fit_transform(corpus).toarray() #get the preprocessed text\n",
    "    \n",
    "    #add sentiment scores to feature vector\n",
    "    X = np.concatenate((X,sentiment_array),axis=1)\n",
    "   \n",
    "    #Splitting\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    #Logistic regression (our main model)\n",
    "    from sklearn.linear_model import LogisticRegression  \n",
    "    classifier = LogisticRegression(random_state=0, solver='lbfgs') \n",
    "    \n",
    "    #Multinomial Naive Bayes (only for the last part)\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    #classifier2 = MultinomialNB().fit(X_train, y_train)\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    #classifier2.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    #Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TP = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TN = cm[1][1]\n",
    "    error_rate = (FP+FN)/(TP+TN+FP+FN) # calculating the error rate based on confusion matrix results\n",
    "    scores.append(error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing out the optimal max features value and plot the results\n",
    "optimal_n = features_n[scores.index(min(scores))]\n",
    "print (\"The optimal number of max vectors is %d\" % optimal_n + \" with an error rate of %.3f\" % min(scores))\n",
    "plt.plot(features_n, scores)\n",
    "plt.xlabel('Number of Max Vectors')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()\n",
    "#plt.savefig('Sarcasm_Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification_report\\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Sarcastic','Not Sarcastic']\n",
    "plt.rcParams[\"figure.figsize\"] = (7,5)\n",
    "normalize = True\n",
    "cm =confusion_matrix(y_test,y_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.GnBu)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "# We want to show all ticks...\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       # ... and label them with the respective list entries\n",
    "       xticklabels=classes, yticklabels=classes,\n",
    "       title= \"Sarcasm Outcomes\",\n",
    "       ylabel='True label',\n",
    "       xlabel='Predicted label')\n",
    "fmt = '.2f' if normalize else 'd'\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.autofmt_xdate()\n",
    "#plt.savefig('Sarcasm_Confusion_Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features_per_class(vectorizer,classifier,n=80):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "    print(\"Important words in non-sarcastic documents\")\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in sarcastic documents\")\n",
    "    for coef, feat in topn_class2:\n",
    "        print(class_labels[1], coef, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        tf.get_feature_names(), classifier.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = dataset['clean_headline'].values  \n",
    "y = dataset['is_sarcastic'].values             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split to train/test\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "#Build simple counts\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6pXf7A78E2H"
   },
   "source": [
    "## Drop `article_link` from dataset. ( 4 marks)\n",
    "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLSVsvrlP9qD"
   },
   "outputs": [],
   "source": [
    "df.drop(columns = 'article_link', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0h6IOxU8OdH"
   },
   "source": [
    "## Get the Length of each line and find the maximum length. ( 8 marks)\n",
    "As different lines are of different length. We need to pad the our sequences using the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRAsChZAQmr3"
   },
   "outputs": [],
   "source": [
    "pos = data.TabularDataset(\n",
    "    path='sarcasm_headlines.txt', format='csv',\n",
    "    csv_reader_params={'delimiter':\"\\t\"},\n",
    "    fields=[('text', TEXT),\n",
    "            ('label', LABEL)])\n",
    "\n",
    "# Split data into 90/10 training/test\n",
    "trainandval, test_data=pos.split(split_ratio=0.90,random_state=random.seed(421))\n",
    "\n",
    "# Of the remaining training data, 80/20 train/validation\n",
    "train_data, valid_data = trainandval.split(split_ratio=0.80,random_state=random.seed(421))\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,sort_key=lambda x: len(x.text),\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum vocabulary, choose word vectors\n",
    "TEXT.build_vocab(train_data,max_size=750, vectors=\"glove.twitter.27B.100d\")\n",
    "LABEL.build_vocab(train_data)\n",
    "#Network Hyperparameters\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "  #round predictions to the closest integer\n",
    "  rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "  correct = (rounded_preds == y).float() #convert into float for division\n",
    "  acc = correct.sum()/len(correct)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  model.train()\n",
    "  for batch in iterator:\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(batch.text).squeeze(1)\n",
    "    loss = criterion(predictions, batch.label)\n",
    "    acc = binary_accuracy(predictions, batch.label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for batch in iterator:\n",
    "      predictions = model(batch.text).squeeze(1)\n",
    "      loss = criterion(predictions, batch.label)\n",
    "      acc = binary_accuracy(predictions, batch.label)\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPPd0YuPXi2M"
   },
   "source": [
    "#**## Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35abKfRx8as3"
   },
   "source": [
    "## Import required modules required for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVel73hYEV4r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ziybaD1RdD9"
   },
   "source": [
    "## Set Different Parameters for the model. ( 4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPw9gAN_EV6m"
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = ## Add your max length here ##\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9abSe-bM8fn9"
   },
   "source": [
    "## Apply Keras Tokenizer of headline column of your data.  ( 8 marks)\n",
    "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
    "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************************************************\")\n",
    "print(\"************** Apply Keras Tokenizer *************\")\n",
    "print(\"**************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9Ad26HfTFMS"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text_data = []\n",
    "for sent in corpus:\n",
    "    doc = word_tokenize(sent)\n",
    "    text_data.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 30\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model1.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12, '0.230*\"trump\" + 0.079*\"donald\" + 0.061*\"house\" + 0.051*\"white\"')\n",
    "(19, '0.056*\"open\" + 0.046*\"office\" + 0.036*\"teacher\" + 0.032*\"happen\"')\n",
    "(17, '0.115*\"obama\" + 0.064*\"leave\" + 0.027*\"explain\" + 0.022*\"believe\"')\n",
    "(14, '0.063*\"star\" + 0.050*\"girl\" + 0.038*\"force\" + 0.030*\"dead\"')\n",
    "(25, '0.044*\"give\" + 0.043*\"self\" + 0.031*\"candidate\" + 0.031*\"couple\"')\n",
    "(0, '0.054*\"work\" + 0.046*\"stop\" + 0.029*\"word\" + 0.027*\"father\"')\n",
    "(27, '0.063*\"want\" + 0.059*\"come\" + 0.050*\"tell\" + 0.045*\"trump\"')\n",
    "(13, '0.049*\"million\" + 0.035*\"food\" + 0.030*\"sign\" + 0.027*\"award\"')\n",
    "(28, '0.074*\"know\" + 0.061*\"need\" + 0.056*\"kill\" + 0.036*\"bush\"')\n",
    "(1, '0.059*\"plan\" + 0.039*\"fight\" + 0.036*\"baby\" + 0.034*\"announce\"')\n",
    "(16, '0.094*\"good\" + 0.071*\"family\" + 0.052*\"friend\" + 0.035*\"movie\"')\n",
    "(2, '0.065*\"like\" + 0.063*\"nation\" + 0.062*\"look\" + 0.059*\"thing\"')\n",
    "(23, '0.067*\"clinton\" + 0.045*\"health\" + 0.038*\"hillary\" + 0.034*\"care\"')\n",
    "(29, '0.044*\"fire\" + 0.029*\"employee\" + 0.025*\"tweet\" + 0.025*\"race\"')\n",
    "(7, '0.041*\"hope\" + 0.039*\"die\" + 0.032*\"mother\" + 0.026*\"line\"')\n",
    "(10, '0.155*\"woman\" + 0.091*\"area\" + 0.056*\"change\" + 0.026*\"climate\"')\n",
    "(21, '0.056*\"state\" + 0.053*\"president\" + 0.037*\"night\" + 0.035*\"deal\"')\n",
    "(11, '0.050*\"election\" + 0.048*\"student\" + 0.034*\"college\" + 0.030*\"body\"')\n",
    "(24, '0.054*\"party\" + 0.050*\"video\" + 0.043*\"bill\" + 0.032*\"bring\"')\n",
    "(3, '0.098*\"report\" + 0.077*\"life\" + 0.056*\"watch\" + 0.051*\"make\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file):\n",
    "    for line in open(file, 'r'):\n",
    "        # use yield since we are interating to each row\n",
    "        # yield produce a sequence of values into generator object\n",
    "        yield json.loads(line)\n",
    "\n",
    "# turn a generator into a list\n",
    "data = list(parse_data('Sarcasm_Headlines_Dataset.json'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "urls = []\n",
    "\n",
    "for item in data:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])\n",
    "    urls.append(item['article_link'])\n",
    "\n",
    "#Stopwords list from https://github.com/Yoast/YoastSEO.js/blob/develop/src/config/stopwords.js\n",
    "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\",\n",
    "             \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\",\n",
    "             \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\",\n",
    "             \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\",\n",
    "             \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\",\n",
    "             \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\",\n",
    "             \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\",\n",
    "             \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\",\n",
    "             \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\",\n",
    "             \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\",\n",
    "             \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\",\n",
    "             \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\",\n",
    "             \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\",\n",
    "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\",\n",
    "             \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\",\n",
    "             \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\",\n",
    "             \"yours\", \"yourself\", \"yourselves\"]\n",
    "\n",
    "for num, sentence in enumerate(sentences):\n",
    "    sentences[num] = ' '.join([w for w in sentence.strip().split() if not w in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of vocabulary words token <OOV>\n",
    "# Tokenizer object used to tokenize sentences\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "# Tokenize a list of sentences\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "# unique words\n",
    "len(word_index)\n",
    "\n",
    "# Encode a list os sentences to use the tokens\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Add  0s at the end of sequence to match the length of the\n",
    "# longest seqeunce\n",
    "padded = pad_sequences(sequences, padding='post')\n",
    "\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Has been created successfully.............................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ffi63KsST3P"
   },
   "source": [
    "## Define X and y for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnjxBdqmSS4s"
   },
   "outputs": [],
   "source": [
    "print(\"********************************************\")\n",
    "print(\"************** Define X and y  *************\")\n",
    "print(\"********************************************\")\n",
    "X = tokenizer.texts_to_sequences(df['headline'])\n",
    "X = pad_sequences(X, maxlen = maxlen)\n",
    "y = np.asarray(df['is_sarcastic'])\n",
    "\n",
    "print(\"Number of Samples:\", len(X))\n",
    "print(X[0])\n",
    "print(\"Number of Labels: \", len(y))\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJLyKg-98rH_"
   },
   "source": [
    "## Get the Vocabulary size ( 4 marks)\n",
    "Hint : You can use tokenizer.word_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*****************************************************\")\n",
    "print(\"************** Size Od the Vocabulary   *************\")\n",
    "print(\"*****************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-2w0gHEUUIo"
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad sequences with zeros\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt', tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hjeMi40XcB1"
   },
   "source": [
    "#**## Word Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "bUF1TuQa8ux0"
   },
   "outputs": [],
   "source": [
    "print(\"****************************************************\")\n",
    "print(\"**************  Glove Word Embeddings **************\")\n",
    "print(\"****************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vq5AIfRtMeZh"
   },
   "outputs": [],
   "source": [
    "glove_file = project_path + \"glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJLX_n2WMecA"
   },
   "outputs": [],
   "source": [
    "#Extract Glove embedding zip file\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(glove_file, 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad sequences with zeros\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt', tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IuXlu8-U3HG"
   },
   "source": [
    "# Get the Word Embeddings using Embedding file as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elZ-T5aFGZmZ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './glove.6B.200d.txt'\n",
    "\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE):\n",
    "    word = o.split(\" \")[0]\n",
    "    # print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    # print(embd)\n",
    "    embeddings[word] = embd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTPxveDmVCrA"
   },
   "source": [
    "# Create a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQgOhiywU9nU"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "len(embeddings.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7IbWuEX82Ra"
   },
   "source": [
    "## Create and Compile your Model  ( 14 marks)\n",
    "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
    "In the end add a final dense layer with sigmoid activation for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7jhsSgYXG4l"
   },
   "outputs": [],
   "source": [
    "### Embedding layer for hint \n",
    "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
    "### Bidirectional LSTM layer for hint \n",
    "## model.add(Bidirectional(LSTM(128, return_sequences = True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Try a simple classifier\n",
    "classifier = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", score)\n",
    "print(\"Precision: %1.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall: %1.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1: %1.3f\\n\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(\"model_history_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y,epochs=50,batch_size=20,validation_split=0.3,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Glove pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt', tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*****************************************\")\n",
    "print(\"**************   CNN Model **************\")\n",
    "print(\"*****************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=maxlen,trainable=True))\n",
    "cnn.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "cnn.add(layers.GlobalMaxPooling1D())\n",
    "cnn.add(layers.Dense(64, activation='relu'))\n",
    "cnn.add(layers.Dropout(0.5))\n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "cnn.add(layers.Dropout(0.5))\n",
    "cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = cnn.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: %1.3f\" % accuracy)\n",
    "loss, accuracy = cnn.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  %1.3f\" % accuracy)\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = [1 if pred > 0.7 else 0 for pred in y_pred]\n",
    "\n",
    "print(\"Precision: %1.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall: %1.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1: %1.3f\\n\" % f1_score(y_test, y_pred))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(cnn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*****************************************\")\n",
    "print(\"*****   Bidirectional(LSTM) layer *******\")\n",
    "print(\"*****************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "lstm = Sequential()\n",
    "lstm.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=maxlen, trainable=True))\n",
    "lstm.add(layers.Bidirectional(layers.LSTM(16, return_sequences=True, recurrent_dropout=0.1, dropout=0.1)))\n",
    "lstm.add(layers.Bidirectional(layers.LSTM(32, recurrent_dropout=0.1, dropout=0.1)))\n",
    "lstm.add(layers.Dense(1, activation='sigmoid')) \n",
    "lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(lstm.summary())\n",
    "\n",
    "history = lstm.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = lstm.evaluate(X_train, y_train, verbose=False)\n",
    "y_pred = lstm.predict(X_test)\n",
    "y_pred = [1 if pred > 0.7 else 0 for pred in y_pred]\n",
    "\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = lstm.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"Precision: %1.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall: %1.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1: %1.3f\\n\" % f1_score(y_test, y_pred))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(lstm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************\")\n",
    "print(\"Testing models\")\n",
    "print(\"**************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm\n",
    "\n",
    "class Session:\n",
    "    def prepareInput(self, text):\n",
    "        return pad_sequences(tokenizer.texts_to_sequences([text]), padding='post', maxlen=maxlen)\n",
    "    \n",
    "    def predict(self, text):\n",
    "        probability = model.predict(self.prepareInput(text))[0][0]\n",
    "        return \"Sarcastic {}\".format(probability) if probability > 0.7 else \"Not sarcastic {}\".format(probability)\n",
    "    \n",
    "    def reply(self, text):\n",
    "        return self.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "\n",
    "print ('[sarcasmBot]: Hi! Write something sarcastic, or not?')\n",
    "print ('[sarcasmBot]: Type \\'end\\' to exit.')\n",
    "\n",
    "inp=\"\"\n",
    "while inp!=\"end\":\n",
    "    inp = input('[User]: ')\n",
    "    print ('[sarcasmBot]:', session.reply(inp))\n",
    "    print ('[sarcasmBot]: write more sarcastic stuff, or not?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJFMxZwMWoTw"
   },
   "source": [
    "## Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 10 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*************************************\")\n",
    "print(\"*****  The validation accuracy ******\")\n",
    "print(\"*************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpVkajCcWnRK"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[inp,af],output=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([X,senti_data],[y],epochs,validation_split=0.2,batch_size,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "plot_model(model, to_file='model_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS=100\n",
    "bestmodelvalue=0\n",
    "for epoch in range(N_EPOCHS):\n",
    "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "  if valid_acc >= bestmodelvalue:\n",
    "    torch.save(model.state_dict(), \"sarcasm_detect_model.pt\")\n",
    "    bestmodelvalue=valid_acc\n",
    "  print(f'Epoch: {epoch+1:02} | Train Acc: {train_acc*100:.2f}% Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"sarcasm_detect_model.pt\"))\n",
    "model.eval()\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(\"Test Accuracy: \",test_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Sarcasm_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
